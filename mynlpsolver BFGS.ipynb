{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import osqp\n",
    "from scipy import sparse\n",
    "from mysqp import NLPBuilder, value_and_jacrev\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = NLPBuilder(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.set_f(\n",
    "    lambda x:x[0] * x[3] * jnp.sum(x[:3]) + x[2]\n",
    ")\n",
    "nlp.add_eq_const(lambda x:jnp.sum(x**2), 40)\n",
    "nlp.add_ineq_const_lb(lambda x:jnp.prod(x), 25)\n",
    "nlp.set_state_bound(jnp.full(4, 1), jnp.full(4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# init\n",
    "x0 = jnp.array([1.0, 5.0, 5.0, 1.0]) # TODO: make initial guess feasible\n",
    "lmbda0 = jnp.zeros(nlp.g_dim+nlp.h_dim)\n",
    "\n",
    "lag_grad_fn = jax.grad(nlp.get_lagrangian_fn())\n",
    "f_grad_fn = jax.grad(nlp.f)\n",
    "const_and_jac_fn = partial(value_and_jacrev, f=nlp.get_gh())\n",
    "eq_dim = nlp.g_dim\n",
    "ineq_dim = nlp.h_dim\n",
    "\n",
    "merit_fn = nlp.get_merit_fn()\n",
    "backtrack = nlp.get_backtrack_fn()\n",
    "fdiff_fn = lambda x1, x2: jnp.abs(nlp.f(x2) - nlp.f(x1))\n",
    "gh_fn = nlp.get_gh()\n",
    "#PqAlu = jax.jit(PqAlu).lower(x0, lmbda0).compile()\n",
    "# merit_fn = jax.jit(merit_fn).lower(x0, 1.).compile()\n",
    "# fdiff_fn = jax.jit(fdiff_fn).lower(x0, x0).compile()\n",
    "qpsolver = osqp.OSQP()\n",
    "\n",
    "is_qp_setup = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(B_prev, lag_grad_curr, lag_grad_prev, x_curr, x_prev):\n",
    "    def constant_zero(B_prev, incr1, incr2):\n",
    "        return B_prev\n",
    "    def normal(B_prev, incr1, incr2):\n",
    "        return B_prev + incr1 - incr2\n",
    "    y = x_curr - x_prev\n",
    "    s = lag_grad_curr - lag_grad_prev\n",
    "    c1 = jnp.inner(y, s)\n",
    "    c2 = s @ B_prev @ s\n",
    "    incr1 = jnp.outer(y, y) / c1\n",
    "    incr2 = B_prev @ jnp.outer(s, s) @ B_prev / c2\n",
    "    cond = jnp.isclose(c1, 0.) | jnp.isclose(c2, 0.)\n",
    "    return jax.lax.cond(cond, constant_zero, normal, B_prev, incr1, incr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x0.copy()\n",
    "lmbda = lmbda0.copy()\n",
    "sigma = 0.\n",
    "it = 0\n",
    "P = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS!\n",
      "QP solved\n",
      "xdiff:4.132376019904824e-12, fdiff:9.947598300641403e-14\n",
      "x:[0.99992547 4.7370438  3.83289496 1.37701724]\n"
     ]
    }
   ],
   "source": [
    "#PqAlu\n",
    "lag_grad_curr = lag_grad_fn(x, lmbda)\n",
    "if P is None:\n",
    "    P = jnp.eye(nlp.dim)\n",
    "else:\n",
    "    P = BFGS(P_prev, lag_grad_curr, lag_grad_prev, x, x_prev)\n",
    "    print(\"BFGS!\")\n",
    "q = f_grad_fn(x)\n",
    "const, const_jac = const_and_jac_fn(x)\n",
    "A, u = const_jac, -const\n",
    "l = jnp.hstack([u[:eq_dim], jnp.full(ineq_dim, -jnp.inf)])\n",
    "\n",
    "#QP\n",
    "Ps = sparse.csc_matrix(P)\n",
    "q = np.asarray(q)\n",
    "As = sparse.csc_matrix(A)\n",
    "l = np.asarray(l)\n",
    "u = np.asarray(u)\n",
    "if is_qp_setup == False:\n",
    "    qpsolver.setup(Ps, q, As, l, u, verbose=False)\n",
    "    is_qp_setup = True\n",
    "else:\n",
    "    qpsolver.update(Px=Ps.data, q=q, Ax=As.data, l=l, u=u)\n",
    "\n",
    "res = qpsolver.solve()\n",
    "if res.info.status != \"solved\":\n",
    "    print(\"QP infeasible!\")\n",
    "else:\n",
    "    print(\"QP solved\")\n",
    "direction = jnp.asarray(res.x)\n",
    "\n",
    "\n",
    "alpha = backtrack(x, direction, merit_fn, beta=1/3, sigma=sigma)\n",
    "xdiff = alpha * direction\n",
    "fdiff = fdiff_fn(x, x + xdiff)\n",
    "\n",
    "#update\n",
    "P_prev = P\n",
    "x_prev = x\n",
    "lag_grad_prev = lag_grad_curr\n",
    "\n",
    "x = x + xdiff\n",
    "lmbda = (1-alpha)*lmbda + alpha * res.y\n",
    "sigma = jnp.max(jnp.abs(jnp.hstack([1.01*res.y, sigma])))\n",
    "\n",
    "print(f\"xdiff:{jnp.linalg.norm(xdiff, jnp.inf)}, fdiff:{fdiff}\")\n",
    "print(f\"x:{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([0.99992547, 4.7370438 , 3.83289496, 1.37701724], dtype=float64),\n",
       " Array([0.99992547, 4.7370438 , 3.83289496, 1.37701724], dtype=float64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_prev, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(False, dtype=bool)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctol = 0.01\n",
    "cl = jnp.hstack([jnp.zeros(nlp.g_dim), jnp.full(nlp.h_dim, -jnp.inf)]) - ctol\n",
    "cu = jnp.zeros(nlp.g_dim+nlp.h_dim) + ctol\n",
    "\n",
    "((cl < gh_fn(x)) & (gh_fn(x) < cu)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.01669514, dtype=float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.max(jnp.hstack([cl - gh_fn(x), gh_fn(x) - cu]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.05768418,  0.04433655, -0.01000727, -3.7475054 , -2.8496766 ,\n",
       "       -0.38134754, -4.009993  , -0.27249455, -1.1703234 , -3.6386526 ],      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fn(x) - cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 3.0654144e-01,  3.0376816e-01,  4.4703484e-05, -3.7556133e+00,\n",
       "       -2.8572013e+00, -3.4639120e-01, -4.0000448e+00, -2.4438667e-01,\n",
       "       -1.1427987e+00, -3.6536088e+00], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True], dtype=bool)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fn(x) < cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 µs ± 1.27 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit PqAul(x0, lmbda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPProb:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.f = None\n",
    "        self._g = [] # eq = 0.\n",
    "        self._h = [] # ineq <= 0.\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_eq_const(fn, val):\n",
    "        result = lambda x: fn(x) - val\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def get_ineq_const_lb(fn, lb):\n",
    "        result = lambda x: -fn(x) + lb\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def get_ineq_const_ub(fn, ub):\n",
    "        result = lambda x: fn(x) - ub\n",
    "        return result\n",
    "    \n",
    "    def get_ineq_const_b(self, fn, lb, ub):\n",
    "        lb_fn = self.get_ineq_const_lb(fn, lb)\n",
    "        ub_fn = self.get_ineq_const_ub(fn, ub)\n",
    "        def result(x):\n",
    "            return jnp.hstack([lb_fn(x), ub_fn(x)])\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_state_bound_fn(lb, ub):\n",
    "        def state_bound_fn(x):\n",
    "            return jnp.hstack([x - ub, -x + lb])\n",
    "        return state_bound_fn\n",
    "    \n",
    "    def set_f(self, fn):\n",
    "        self.f = fn\n",
    "    \n",
    "    def add_eq_const(self, fn, val):\n",
    "        self._g.append(self.get_eq_const(fn, val))\n",
    "\n",
    "    def add_ineq_const_lb(self, fn, lb):\n",
    "        self._h.append(self.get_ineq_const_lb(fn, lb))\n",
    "    \n",
    "    def add_ineq_const_ub(self, fn, ub):\n",
    "        self._h.append(self.get_ineq_const_ub(fn, ub))\n",
    "\n",
    "    def add_ineq_const_b(self, fn, lb, ub):\n",
    "        self._h.append(self.get_ineq_const_lb(fn, lb))\n",
    "        self._h.append(self.get_ineq_const_ub(fn, ub))\n",
    "    \n",
    "    def set_state_bound(self, xlb, xub):\n",
    "        self._h.append(self.get_state_bound_fn(xlb, xub))\n",
    "    \n",
    "    def get_g(self):\n",
    "        return lambda x: jnp.hstack([fn(x) for fn in self._g])\n",
    "    \n",
    "    def get_h(self):\n",
    "        return lambda x: jnp.hstack([fn(x) for fn in self._h])\n",
    "\n",
    "    def get_gh(self):\n",
    "        return lambda x: jnp.hstack([fn(x) for fn in self._g+self._h])\n",
    "    \n",
    "    def get_lagrangian(self):\n",
    "        gh = self.get_gh()\n",
    "        return lambda x, lmbda: self.f(x) + gh(x) @ lmbda\n",
    "    \n",
    "    def get_g_dim(self):\n",
    "        g = self.get_g()\n",
    "        return len(g(jnp.zeros(self.dim)))\n",
    "    \n",
    "    def get_h_dim(self):\n",
    "        h = self.get_h()\n",
    "        return len(h(jnp.zeros(self.dim)))\n",
    "    \n",
    "    def get_lag_mult_dim(self):\n",
    "        gh = self.get_gh()\n",
    "        return len(gh(jnp.zeros(self.dim)))\n",
    "    \n",
    "    def get_merit_fn(self):\n",
    "        sigma = 1.0\n",
    "        f = self.f\n",
    "        g = self.get_g()\n",
    "        h = self.get_h()\n",
    "        def merit_fn(x):\n",
    "            eq_norm = jnp.linalg.norm(g(x), 1)\n",
    "            ineq_norm = jnp.linalg.norm(jnp.clip(h(x), a_min=0), 1)\n",
    "            return f(x) + sigma * (eq_norm + ineq_norm)\n",
    "        return merit_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrack(\n",
    "    x_k,\n",
    "    direction,\n",
    "    merit_fn,\n",
    "    alpha=1.,\n",
    "    beta=0.5,\n",
    "    max_iter=30,\n",
    "):\n",
    "    curr_merit = merit_fn(x_k)\n",
    "    next_merit = merit_fn(x_k + alpha * direction)\n",
    "\n",
    "    n_iter = 0\n",
    "    while (next_merit >= curr_merit) and (n_iter < max_iter):\n",
    "        alpha *= beta\n",
    "        next_merit = merit_fn(x_k + alpha * direction)\n",
    "        n_iter += 1\n",
    "    if n_iter == max_iter:\n",
    "        print(f'Backtracking failed to find alpha after {max_iter} iterations!')\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = NLPProb(4)\n",
    "prob.set_f(\n",
    "    lambda x:x[0] * x[3] * jnp.sum(x[:3]) + x[2]\n",
    ")\n",
    "prob.add_eq_const(lambda x:jnp.sum(x**2), 40)\n",
    "prob.add_ineq_const_lb(lambda x:jnp.prod(x), 25)\n",
    "prob.set_state_bound(jnp.full(4, 1), jnp.full(4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_hess = jax.hessian(prob.get_lagrangian())\n",
    "f_grad = jax.grad(prob.f)\n",
    "gh = prob.get_gh()\n",
    "gh_grad = jax.jacrev(prob.get_gh())\n",
    "merit_fn = prob.get_merit_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "x0 = jnp.array([1.0, 5.0, 5.0, 1.0])\n",
    "lmbda0 = jnp.zeros(prob.get_lag_mult_dim())\n",
    "x = x0.copy()\n",
    "lmbda = lmbda0.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_dim = prob.get_g_dim()\n",
    "ineq_dim = prob.get_h_dim()\n",
    "P = lag_hess(x, jnp.zeros(10))\n",
    "q = f_grad(x)\n",
    "A = gh_grad(x)\n",
    "u = -gh(x)\n",
    "l = jnp.hstack([u[:eq_dim], jnp.full(ineq_dim, -jnp.inf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "if jnp.isnan(jnp.linalg.cholesky(P)).any():\n",
    "    eigs, vecs = jnp.linalg.eigh(P)\n",
    "    delta = 1e-6\n",
    "    eigs_modified = jnp.where(eigs < delta, delta, eigs)\n",
    "    P = vecs @ jnp.diag(eigs_modified) @ vecs.T\n",
    "\n",
    "P = sparse.csc_matrix(P)\n",
    "q = np.asarray(q)\n",
    "A = sparse.csc_matrix(A)\n",
    "l = np.asarray(l)\n",
    "u = np.asarray(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QP solved\n"
     ]
    }
   ],
   "source": [
    "solver = osqp.OSQP()\n",
    "solver.setup(P, q, A, l, u, verbose=False)\n",
    "res = solver.solve()\n",
    "if res.info.status != \"solved\":\n",
    "    print(\"QP infeasible!\")\n",
    "else:\n",
    "    print(\"QP solved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_merit:17.231197357177734, next_merit:17.224365234375\n",
      "x:[1.0000093 4.8189845 3.7490077 1.3751227], alpha:0.0625\n"
     ]
    }
   ],
   "source": [
    "direction = jnp.asarray(res.x)\n",
    "alpha = backtrack(x, direction, merit_fn)\n",
    "print(f\"curr_merit:{merit_fn(x)}, next_merit:{merit_fn(x+direction*alpha)}\")\n",
    "print(f\"x:{x}, alpha:{alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "x += alpha * direction\n",
    "lmbda = (1-alpha)*lmbda + alpha * res.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_consts = [eq_const]  # = 0.\n",
    "ineq_consts = [ineq_const, state_bound] # <= 0.\n",
    "consts_fns = [] + eq_consts + ineq_consts\n",
    "_g = lambda x: jnp.hstack([c_fn(x) for c_fn in consts_fns])\n",
    "n_eq = len(eq_consts)\n",
    "n_ineq = len(ineq_consts)\n",
    "lbg, ubg = jnp.zeros(n_eq), jnp.zeros(n_eq)\n",
    "lbh, ubh = jnp.zeros(n_ineq), jnp.full(n_ineq, jnp.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lagrangian\n",
    "lag = lambda x, lmbda: f(x) + _g(x) @ lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_hess = jax.hessian(lag)\n",
    "f_grad = jax.grad(f)\n",
    "g_grad = jax.jacrev(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = lag_hess(x0, lmbda0)\n",
    "grad_f = np.asarray(f_grad(x0))\n",
    "grad_g = g_grad(x0)\n",
    "val_g = _g(x0)\n",
    "lbg = np.array([0., 25])\n",
    "ubg = np.array([40., jnp.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prob = osqp.OSQP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "           OSQP v0.6.2  -  Operator Splitting QP Solver\n",
      "              (c) Bartolomeo Stellato,  Goran Banjac\n",
      "        University of Oxford  -  Stanford University 2021\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 4, constraints m = 2\n",
      "          nnz(P) + nnz(A) = 18\n",
      "settings: linear system solver = qdldl,\n",
      "          eps_abs = 1.0e-03, eps_rel = 1.0e-03,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 4000\n",
      "          check_termination: on (interval 25),\n",
      "          scaling: on, scaled_termination: off\n",
      "          warm start: on, polish: off, time_limit: off\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob.setup(sparse.csc_matrix(B), grad_f, sparse.csc_matrix(grad_g), lbg, ubg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   objective    pri res    dua res    rho        time\n",
      "   1  -3.0971e+04   4.00e+01   9.60e+03   1.00e-01   1.22e-04s\n",
      "  25  -1.0000e+30   1.23e-02   1.01e+00   1.00e-01   5.41e-04s\n",
      "\n",
      "status:               dual infeasible\n",
      "number of iterations: 25\n",
      "run time:             7.19e-04s\n",
      "optimal rho estimate: 3.77e-03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, None, None, None], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim = 4\n",
    "n_eq, n_ineq = 1, 1\n",
    "n_s = 2* n_eq + n_g\n",
    "new_B = jnp.block([\n",
    "    B, jnp.zeros((n_dim, ))\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
